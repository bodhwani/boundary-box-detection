{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneratingCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mjqHNGYxZEyT",
        "colab_type": "code",
        "outputId": "2e878312-1dae-4b3d-df89-0bc880e29792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#DEPENDENCIES\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model,load_model\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler,ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras.losses\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from keras import metrics\n",
        "from PIL import Image\n",
        "print (\"Installed dependencies\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Installed dependencies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "whscN0EQKtsg",
        "colab_type": "code",
        "outputId": "adb61afa-41bd-4b9b-e063-68fc535cd42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2P07Wq_nLhdP",
        "colab_type": "code",
        "outputId": "552b573d-f4d0-4334-ae75-70f0681134fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#checking \n",
        "import os \n",
        "print(os.listdir(\"/content/drive/My Drive\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Colab Notebooks', 'train', 'dataset', 'training_set.csv', 'test', 'model.h5', 'model2.h5', 'model3_weights.h5', 'model3.h5', 'model4_weights.h5', 'model4_6.h5', 'model4_weights_6.h5', 'model4_5.h5', 'model4_weights_7.h5', 'model4.h5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F7AzhiyhKmuj",
        "colab_type": "code",
        "outputId": "e4065693-3e65-4233-b34e-b729881fca5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4131
        }
      },
      "cell_type": "code",
      "source": [
        "id_to_box={}\n",
        "data=pd.read_csv('/content/drive/My Drive/training_set.csv')\n",
        "for index,row in data.iterrows():\n",
        "    box=np.array([row[\"x1\"],row[\"y1\"],row[\"x2\"]-row[\"x1\"],row[\"y2\"]-row[\"y1\"]])\n",
        "    box[0]=box[0]/640*224\n",
        "    box[1]=box[1]/480*224\n",
        "    box[2]=box[2]/640*224  \n",
        "    box[3]=box[3]/480*224\n",
        "    id_to_box[index]=box\n",
        "    if(index%100==0):\n",
        "        print(index)\n",
        "print(len(data))\n",
        "print(\"DATA PREPARED\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "10000\n",
            "10100\n",
            "10200\n",
            "10300\n",
            "10400\n",
            "10500\n",
            "10600\n",
            "10700\n",
            "10800\n",
            "10900\n",
            "11000\n",
            "11100\n",
            "11200\n",
            "11300\n",
            "11400\n",
            "11500\n",
            "11600\n",
            "11700\n",
            "11800\n",
            "11900\n",
            "12000\n",
            "12100\n",
            "12200\n",
            "12300\n",
            "12400\n",
            "12500\n",
            "12600\n",
            "12700\n",
            "12800\n",
            "12900\n",
            "13000\n",
            "13100\n",
            "13200\n",
            "13300\n",
            "13400\n",
            "13500\n",
            "13600\n",
            "13700\n",
            "13800\n",
            "13900\n",
            "14000\n",
            "14100\n",
            "14200\n",
            "14300\n",
            "14400\n",
            "14500\n",
            "14600\n",
            "14700\n",
            "14800\n",
            "14900\n",
            "15000\n",
            "15100\n",
            "15200\n",
            "15300\n",
            "15400\n",
            "15500\n",
            "15600\n",
            "15700\n",
            "15800\n",
            "15900\n",
            "16000\n",
            "16100\n",
            "16200\n",
            "16300\n",
            "16400\n",
            "16500\n",
            "16600\n",
            "16700\n",
            "16800\n",
            "16900\n",
            "17000\n",
            "17100\n",
            "17200\n",
            "17300\n",
            "17400\n",
            "17500\n",
            "17600\n",
            "17700\n",
            "17800\n",
            "17900\n",
            "18000\n",
            "18100\n",
            "18200\n",
            "18300\n",
            "18400\n",
            "18500\n",
            "18600\n",
            "18700\n",
            "18800\n",
            "18900\n",
            "19000\n",
            "19100\n",
            "19200\n",
            "19300\n",
            "19400\n",
            "19500\n",
            "19600\n",
            "19700\n",
            "19800\n",
            "19900\n",
            "20000\n",
            "20100\n",
            "20200\n",
            "20300\n",
            "20400\n",
            "20500\n",
            "20600\n",
            "20700\n",
            "20800\n",
            "20900\n",
            "21000\n",
            "21100\n",
            "21200\n",
            "21300\n",
            "21400\n",
            "21500\n",
            "21600\n",
            "21700\n",
            "21800\n",
            "21900\n",
            "22000\n",
            "22100\n",
            "22200\n",
            "22300\n",
            "22400\n",
            "22500\n",
            "22600\n",
            "22700\n",
            "22800\n",
            "22900\n",
            "23000\n",
            "23100\n",
            "23200\n",
            "23300\n",
            "23400\n",
            "23500\n",
            "23600\n",
            "23700\n",
            "23800\n",
            "23900\n",
            "24000\n",
            "DATA PREPARED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TmKgXchOOsHO",
        "colab_type": "code",
        "outputId": "c5dd843b-9f77-46a9-ffa9-9a4ee13e5529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(data.iloc[1600][\"image_name\"])\n",
        "batch_size=256"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JPEG_20161123_162037_1000876798530.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AJGha3LzLEFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=256, dim=(224,224), n_channels=3,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size, 4), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            image=Image.open(\"/content/drive/My Drive/dataset/\"+data.iloc[ID][\"image_name\"]).convert('RGB')\n",
        "            image=image.resize((224,224))\n",
        "            image=np.array(image,dtype=np.float32)\n",
        "            image=image/255\n",
        "            image=Normalize(image,[0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "            X[i,] = image\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rp46byzNMJdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Normalize(image,mean,std):\n",
        "    for channel in range(3):\n",
        "        image[:,:,channel]=(image[:,:,channel]-mean[channel])/std[channel]\n",
        "    return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2x4CMra-L4_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {'dim': (224,224),\n",
        "          'batch_size': batch_size,\n",
        "          'n_classes': 10,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Datasets\n",
        "partition = {a:a for a in range(len(data))}\n",
        "labels = id_to_box\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition, labels, **params)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Pvd-T--_VKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# metric function\n",
        "def my_metric(labels,predictions):\n",
        "    \n",
        "    threshhold=0.75\n",
        "    x=predictions[:,0]*224\n",
        "    x=tf.maximum(tf.minimum(x,224.0),0.0)\n",
        "    y=predictions[:,1]*224\n",
        "    y=tf.maximum(tf.minimum(y,224.0),0.0)\n",
        "    width=predictions[:,2]*224\n",
        "    width=tf.maximum(tf.minimum(width,224.0),0.0)\n",
        "    height=predictions[:,3]*224\n",
        "    height=tf.maximum(tf.minimum(height,224.0),0.0)\n",
        "    label_x=labels[:,0]\n",
        "    label_y=labels[:,1]\n",
        "    label_width=labels[:,2]\n",
        "    label_height=labels[:,3]\n",
        "    a1=tf.multiply(width,height)\n",
        "    a2=tf.multiply(label_width,label_height)\n",
        "    x1=tf.maximum(x,label_x)\n",
        "    y1=tf.maximum(y,label_y)\n",
        "    x2=tf.minimum(x+width,label_x+label_width)\n",
        "    y2=tf.minimum(y+height,label_y+label_height)\n",
        "    IoU=tf.abs(tf.multiply((x1-x2),(y1-y2)))/(a1+a2-tf.abs(tf.multiply((x1-x2),(y1-y2))))\n",
        "    condition=tf.less(threshhold,IoU)\n",
        "    sum=tf.where(condition,tf.ones(tf.shape(condition)),tf.zeros(tf.shape(condition)))\n",
        "    print (\"sum is \",tf.reduce_mean(sum))\n",
        "    return tf.reduce_mean(sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYZk9LRIXmKu",
        "colab_type": "code",
        "outputId": "98707674-0c71-4a2f-a048-63eb2cca86ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2703
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# loss function\n",
        "def smooth_l1_loss(true_box,pred_box):\n",
        "    loss=0.0\n",
        "   \n",
        "    for i in range(4):\n",
        "        residual=tf.abs(true_box[:,i]-pred_box[:,i]*224)\n",
        "        condition=tf.less(residual,1.0)\n",
        "        small_res=0.5*tf.square(residual)\n",
        "        large_res=residual-0.5\n",
        "        loss=loss+tf.where(condition,small_res,large_res)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def resnet_block(inputs,num_filters,kernel_size,strides,activation='relu'):\n",
        "    x=Conv2D(num_filters,kernel_size=kernel_size,strides=strides,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(inputs)\n",
        "    x=BatchNormalization()(x)\n",
        "    if(activation):\n",
        "        x=Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet18():\n",
        "    inputs=Input((224,224,3))\n",
        "    \n",
        "    # conv1\n",
        "    x=resnet_block(inputs,64,[7,7],2)\n",
        "\n",
        "    # conv2\n",
        "    x=MaxPooling2D([3,3],2,'same')(x)\n",
        "    for i in range(2):\n",
        "        a=resnet_block(x,64,[3,3],1)\n",
        "        b=resnet_block(a,64,[3,3],1,activation=None)\n",
        "        x=keras.layers.add([x,b])\n",
        "        x=Activation('relu')(x)\n",
        "    \n",
        "    # conv3\n",
        "    a=resnet_block(x,128,[1,1],2)\n",
        "    b=resnet_block(a,128,[3,3],1,activation=None)\n",
        "    x=Conv2D(128,kernel_size=[1,1],strides=2,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(x)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    a=resnet_block(x,128,[3,3],1)\n",
        "    b=resnet_block(a,128,[3,3],1,activation=None)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    # conv4\n",
        "    a=resnet_block(x,256,[1,1],2)\n",
        "    b=resnet_block(a,256,[3,3],1,activation=None)\n",
        "    x=Conv2D(256,kernel_size=[1,1],strides=2,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(x)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    a=resnet_block(x,256,[3,3],1)\n",
        "    b=resnet_block(a,256,[3,3],1,activation=None)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    # conv5\n",
        "    a=resnet_block(x,512,[1,1],2)\n",
        "    b=resnet_block(a,512,[3,3],1,activation=None)\n",
        "    x=Conv2D(512,kernel_size=[1,1],strides=2,padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(x)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    a=resnet_block(x,512,[3,3],1)\n",
        "    b=resnet_block(a,512,[3,3],1,activation=None)\n",
        "    x=keras.layers.add([x,b])\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    x=AveragePooling2D(pool_size=7,data_format=\"channels_last\")(x)\n",
        "    # out:1*1*512\n",
        "\n",
        "    y=Flatten()(x)\n",
        "    # out:512\n",
        "    y=Dense(1000,kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(y)\n",
        "    outputs=Dense(4,kernel_initializer='he_normal',kernel_regularizer=l2(1e-3))(y)\n",
        "    \n",
        "    model=Model(inputs=inputs,outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "keras.losses.smooth_l1_loss = smooth_l1_loss\n",
        "model = resnet18()\n",
        "\n",
        "\n",
        "model.compile(loss=\"smooth_l1_loss\",optimizer=Adam(),metrics=['accuracy',my_metric])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "def lr_sch(epoch):\n",
        "    #200 total\n",
        "    if epoch <50:\n",
        "        return 1e-3\n",
        "    if 50<=epoch<100:\n",
        "        return 1e-4\n",
        "    if epoch>=100:\n",
        "        return 1e-5\n",
        "\n",
        "lr_scheduler=LearningRateScheduler(lr_sch)\n",
        "\n",
        "lr_reducer=ReduceLROnPlateau(monitor='my_metric',factor=0.2,patience=5,mode='max',min_lr=1e-3)\n",
        "\n",
        "checkpoint=ModelCheckpoint('/content/drive/My Drive/model4.h5',monitor='my_metric',verbose=0,save_best_only=True,mode='auto')\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/model4_weights_9.h5')\n",
        "\n",
        "model_details=model.fit_generator(generator=training_generator,epochs=10,shuffle=True,callbacks=[lr_scheduler,lr_reducer,checkpoint],verbose=1)\n",
        "\n",
        "model.save('/content/drive/My Drive/model4.h5')\n",
        "\n",
        "print (\"Model saved\")\n",
        "\n",
        "model.save_weights('/content/drive/My Drive/model4_weights_10.h5')\n",
        "\n",
        "print (\"Model weights saved\")\n",
        "\n",
        "#scores=model.evaluate(data_test,box_test,verbose=1)\n",
        "\n",
        "#print('Test loss : ',scores[0])\n",
        "#print('Test accuracy : ',scores[1])\n",
        "\n",
        "#plot_model(model_details)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum is  Tensor(\"metrics_8/my_metric/Mean:0\", shape=(), dtype=float32)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 112, 112, 64) 9472        input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 112, 112, 64) 256         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 112, 112, 64) 0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 56, 56, 64)   36928       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 56, 56, 64)   256         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 56, 56, 64)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 56, 56, 64)   36928       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 56, 56, 64)   256         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 56, 56, 64)   0           max_pooling2d_9[0][0]            \n",
            "                                                                 batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 56, 56, 64)   0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 56, 56, 64)   36928       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 56, 56, 64)   256         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 56, 56, 64)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 56, 56, 64)   36928       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 56, 56, 64)   256         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 56, 56, 64)   0           activation_139[0][0]             \n",
            "                                                                 batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 56, 56, 64)   0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 28, 28, 128)  8320        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 28, 28, 128)  512         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 28, 28, 128)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 28, 28, 128)  147584      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 28, 28, 128)  8320        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 28, 28, 128)  512         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 28, 28, 128)  0           conv2d_168[0][0]                 \n",
            "                                                                 batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 28, 28, 128)  0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 28, 28, 128)  147584      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 28, 28, 128)  512         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 28, 28, 128)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 28, 28, 128)  147584      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 28, 28, 128)  512         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 28, 28, 128)  0           activation_143[0][0]             \n",
            "                                                                 batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 28, 28, 128)  0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 14, 14, 256)  33024       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 14, 14, 256)  1024        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 14, 14, 256)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 14, 14, 256)  590080      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 14, 14, 256)  33024       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 14, 14, 256)  1024        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 14, 14, 256)  0           conv2d_173[0][0]                 \n",
            "                                                                 batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 14, 14, 256)  0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 14, 14, 256)  590080      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 14, 14, 256)  1024        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 14, 14, 256)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 14, 14, 256)  590080      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 14, 14, 256)  1024        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 14, 14, 256)  0           activation_147[0][0]             \n",
            "                                                                 batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 14, 14, 256)  0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 7, 7, 512)    131584      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 512)    2048        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 512)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 7, 7, 512)    2359808     activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 7, 7, 512)    131584      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 512)    2048        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 7, 7, 512)    0           conv2d_178[0][0]                 \n",
            "                                                                 batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 512)    0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 7, 7, 512)    2359808     activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 512)    2048        conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 512)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 7, 7, 512)    2359808     activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 512)    2048        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 7, 7, 512)    0           activation_151[0][0]             \n",
            "                                                                 batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 512)    0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 1, 1, 512)    0           activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 512)          0           average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 1000)         513000      flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 4)            4004        dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 10,328,076\n",
            "Trainable params: 10,320,268\n",
            "Non-trainable params: 7,808\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "93/93 [==============================] - 500s 5s/step - loss: 8.3324 - acc: 0.9771 - my_metric: 0.9922\n",
            "Epoch 2/10\n",
            "93/93 [==============================] - 446s 5s/step - loss: 7.4757 - acc: 0.9796 - my_metric: 0.9959\n",
            "Epoch 3/10\n",
            " 4/93 [>.............................] - ETA: 7:24 - loss: 6.8007 - acc: 0.9814 - my_metric: 0.9941"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}